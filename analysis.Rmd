---
title: "Prediction Assignment Writeup"
author: "Haron Shihab"
date: "Sunday, October 26, 2014"
output: html_document
---

This is part 1 of the Practical machine learning course project

###Background
In this project, the goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict how well they did the excersice, this is expressed in the **classe** variable. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website [here](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).


###Data
The datasets used in this project can be found at:

* The training data for this project are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

* The test data are available here: 

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

###Data analysis

####Pre-requisite libraries
```{r}
library(caret)
library(ggplot2)
library(randomForest)

set.seed(0)
```

####Loading the data
```{r}
#get the data files
if (!file.exists("./data/pml-training.csv")){
	download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
		      "./data/pml-training.csv")
}

#load the training data into R
data <- read.csv("data/pml-training.csv", na.strings = c("NA", ""))
dim(data)
```

####Data partitioning
Now, we are going to creat a training set and a testing set from our training data only. we do this to see how well our model does without actually using the external data set.

```{r}
#partition the data (70% training; 30% testing)
inTrain <- createDataPartition(y = data$classe, p = 0.7, list = FALSE)
training <- data[inTrain, ]
testing <- data[-inTrain, ]

dim(training)
```

####Handling NA's in the data
There quite a few number of NA's in the data, the *caret::train* function cannot have these NA's, so we are going to clean up the training data and remove all columns with NA's.

```{r}
#see how NA's are distributed among the data
nas <- sapply(training, function(x) sum(is.na(x)))
table(nas)
```

Now, let's take a look at the data after removing columns full of NA's, also the first few columns of the training set are not variables to be considered as predictors(i.e columns like the person who did the measurements, some time variables etc.)
```{r}
#remove FULL NA cols
bad.cols <- names(nas[nas == 13460])
training <- training[, !names(training) %in% bad.cols]
training <- training[, -c(1:7)]
names(training)
```


###Model training
We are going to traing our random forests model to predict the classe variable from all other variables.

**Note: I saved the output model in an rds file because the training is very time consuming**
```{r, eval=FALSE}
#train using random forests model
modelFit <- train(classe ~ ., method = "rf", data = training)
saveRDS(modelFit, "rf.RDS")
```

```{r}
modelFit <- readRDS("rf.RDS")
```

###Model evaluation
It's time to use the leftout *testing* data set to evaluate how well our model is.
we can do this using a confusion matrix

```{r}
#calculate the accuracy of our prediction
mean(testing$class == predict(modelFit, testing))
```

We can see that the Accuracy is 99.3%, and that would mean that our out of sample error rate would be 0.07 (1 - out of sample accuracy)
